{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d2l_7.7_DenseNet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4XvC/mlDBO8ynyu5eNTqg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forMwish/MyDeepLearn/blob/master/d2l_7_7_DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X5SSDAqtoZZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 准备"
      ],
      "metadata": {
        "id": "bo_lOangodXE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjDcbf_9oQwv"
      },
      "outputs": [],
      "source": [
        "# 挂载 gdrive，选择\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "gdrive_path = '/gdrive'\n",
        "drive.mount(gdrive_path, force_remount=True)\n",
        "\n",
        "os.chdir(\"%s/MyDrive\"%gdrive_path)\n",
        "try:\n",
        "    os.mkdir(\"./d2l_7.7\")\n",
        "    os.chdir(\"./d2l_7.7\")\n",
        "except:\n",
        "    os.chdir(\"./d2l_7.7\")\n",
        "\n",
        "# 安装 d2l\n",
        "os.system(\"pip install d2l==0.17.5\")\n",
        "\n",
        "# 解决 matplot 相关问题\n",
        "os.system(\"pip uninstall matplotlib\")\n",
        "os.system(\"pip install matplotlib==3.1.3\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 其它配置\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# notebook 设置tag补全\n",
        "%config Completer.use_jedi = False\n",
        "\n",
        "# 优先使用 gpu 设备\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"use device:\", device)\n",
        "\n",
        "# pyplot 使用黑暗模式\n",
        "plt.style.use(\"default\")\n",
        "# plt.style.use(\"dark_background\")\n",
        "\n",
        "# pytorch 随机种子固定\n",
        "torch.manual_seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# numpy 随机种子固定\n",
        "np.random.seed(0)\n",
        "\n",
        "# python 随机种子固定\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "V6L00o91obFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 开始"
      ],
      "metadata": {
        "id": "RS73kOxzoiSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "def get_data_iter(batch_size):\n",
        "  \"\"\" 返回 fashion MNIST 的训练迭代器和测试迭代器\n",
        "  \"\"\"\n",
        "  trans = transforms.ToTensor()\n",
        "  mnist_train = torchvision.datasets.FashionMNIST(\"./\", train=True, download=True, transform=trans)\n",
        "  mnist_test = torchvision.datasets.FashionMNIST(\"./\", train=False, download=True, transform=trans)\n",
        "\n",
        "  train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  test_iter  = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "  return (train_iter, test_iter)"
      ],
      "metadata": {
        "id": "waoBN3fZoju3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 统计精确个数\n",
        "def accuracy_num(y_hat, y):\n",
        "    \"\"\"分类问题，统计精确个数\n",
        "    \"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "        cmp = y_hat.type(y.dtype) == y\n",
        "    return float(cmp.type(y.dtype).sum())\n",
        "\n",
        "def parse_gradient(net:torch.nn.Module):\n",
        "    \"\"\"返回模型每层名称、梯度和、梯度均值、梯度方差的字典\n",
        "    \"\"\"\n",
        "    layer_name = []\n",
        "    grad_sum = []\n",
        "    grad_mean = []\n",
        "    grad_var = []\n",
        "    for i, param in enumerate(net.named_parameters()):\n",
        "        layer_name.append(param[0])\n",
        "        grad_sum.append(param[1].grad.sum().cpu().numpy().tolist())\n",
        "        grad_mean.append(param[1].grad.mean().cpu().numpy().tolist())\n",
        "        grad_var.append(param[1].grad.var().cpu().numpy().tolist())\n",
        "        # print(f\"layer:{param[0]:20} sum:{param[1].grad.sum():10.4} mean:{param[1].grad.mean():10.4} var:{param[1].grad.var():10.4}\")\n",
        "    return {\"layer\":layer_name,\n",
        "            \"grad_sum\":grad_sum,\n",
        "            \"grad_mean\":grad_mean,\n",
        "            \"grad_var\":grad_var\n",
        "            }"
      ],
      "metadata": {
        "id": "gwZrDZ9nonUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class Timer:\n",
        "    def begin(self):\n",
        "        self.start = time.time()\n",
        "    def get(self):\n",
        "        \"\"\" 返回 begin 到 get 之间的耗时(s)\n",
        "        \"\"\"\n",
        "        self.end = time.time()\n",
        "        return self.end - self.start\n",
        "    def restart(self):\n",
        "        \"\"\" 返回 begin 到 get 之间的耗时(s), 并重新初始化 begin\n",
        "        \"\"\"\n",
        "        self.end = time.time()\n",
        "        ret = self.end - self.start\n",
        "        self.start = self.end\n",
        "        return ret"
      ],
      "metadata": {
        "id": "GTTExPsjooPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 每个 epoch 显示训练结果（loss & acc）\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "%matplotlib inline\n",
        "\n",
        "class PlotFrames:\n",
        "    \"\"\" 将传入的多个 pd.frame 依次调用 pyplot.plot 制图，frame 和 plot 对应关系如下：\n",
        "            frame -> axes\n",
        "            frame 的每个列 -> 单个 plot (列 label 对应曲线 label)\n",
        "    \"\"\"\n",
        "    def __init__(self, frame_num, figsize=(10, 10), title=[]):\n",
        "        self.fig, self.axes = plt.subplots(frame_num, 1, figsize=figsize)\n",
        "        if not isinstance(self.axes, np.ndarray):\n",
        "            self.axes = [self.axes]\n",
        "        self.title = title\n",
        "        \n",
        "    def update(self, *frames:pd.DataFrame):\n",
        "        for i, frame in enumerate(frames):\n",
        "            self.axes[i].cla()        \n",
        "            self.axes[i].grid()        \n",
        "\n",
        "            for j, column in enumerate(frame.columns):\n",
        "                y = frame.loc[:, column].values\n",
        "                x = np.arange(len(y))\n",
        "                label = column\n",
        "                if len(self.title) == len(frames):\n",
        "                    self.axes[i].set_title(self.title[i])\n",
        "                self.axes[i].plot(x, y, label=f\"{label} {y[-1]:10.3} max:{y.max():5.3} min:{y.min():5.3}\")\n",
        "                # self.axes[i].plot(x, y, label=f\" {y[-1]:10.3} max:{y.max():5.3} min:{y.min():5.3}\")\n",
        "                self.axes[i].legend()\n",
        "\n",
        "        display.display(self.fig)\n",
        "        display.clear_output(wait=True)\n",
        "    \n",
        "    def save(self, path):\n",
        "        self.fig.savefig(path)"
      ],
      "metadata": {
        "id": "wbHaXk75or7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_iter, test_iter, num_epochs, lr, device, save_csv, init=True):\n",
        "    def init_weight(m):\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "    if init:\n",
        "        net.apply(init_weight)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    title = [\"grad_sum\", \"grad_mean\", \"grad_var\", \"loss\", \"acc\", \"time\"]\n",
        "    grad_plot = PlotFrames(len(title), figsize=(40, 30), title=title) # 分别是 和、均值、方差\n",
        "    t = Timer()\n",
        "    t_list_train = []\n",
        "    t_list_test = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        t.begin()\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            optimizer.zero_grad()\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i == 0:\n",
        "                train_metric = np.zeros((3, 1)) # 损失和、准确度和、样本数\n",
        "            train_metric += np.array([(l.sum()).detach().cpu().numpy(), \n",
        "                                accuracy_num(y_hat.cpu(), y.cpu()), y.cpu().numel()]).reshape(3, -1)\n",
        "        t_train = t.restart()\n",
        "\n",
        "        grad_data = parse_gradient(net)\n",
        "        t_grad = t.restart()\n",
        "\n",
        "        # 验证\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (X, y) in enumerate(test_iter):\n",
        "                if isinstance(X, list):\n",
        "                    # BERT微调所需的（之后将介绍）\n",
        "                    X = [x.to(device) for x in X]\n",
        "                else:\n",
        "                    X = X.to(device)\n",
        "                y = y.to(device)\n",
        "                y_hat = net(X)\n",
        "                \n",
        "                if i == 0:\n",
        "                    test_metric = np.zeros((3, 1)) # 损失和、准确度和、样本数\n",
        "                test_metric += np.array([(l.sum()).detach().cpu().numpy(), \n",
        "                                    accuracy_num(y_hat.cpu(), y.cpu()), y.cpu().numel()]).reshape(3, -1)\n",
        "        t_test = t.get()\n",
        "\n",
        "\n",
        "        pd_c = np.array(grad_data['layer'])\n",
        "        pd_d0 = np.array(grad_data['grad_sum']).reshape((1, -1))\n",
        "        pd_d1 = np.array(grad_data['grad_mean']).reshape((1, -1))\n",
        "        pd_d2 = np.array(grad_data['grad_var']).reshape((1, -1))\n",
        "        if epoch == 0:\n",
        "            grad_pd_sum  = pd.DataFrame(pd_d0, columns=pd_c)\n",
        "            grad_pd_mean = pd.DataFrame(pd_d1, columns=pd_c)\n",
        "            grad_pd_var  = pd.DataFrame(pd_d2, columns=pd_c)\n",
        "            \n",
        "            loss_pd = pd.DataFrame(np.append(train_metric[0]/train_metric[2], test_metric[0]/test_metric[2]).reshape(1, -1), columns=[\"train\", \"test\"])\n",
        "            acc_pd  = pd.DataFrame(np.append(train_metric[1]/train_metric[2], test_metric[1]/test_metric[2]).reshape(1, -1), columns=[\"train\", \"test\"])\n",
        "\n",
        "            time_pd = pd.DataFrame([[t_train, t_grad, t_test]], columns=[\"train\", \"grad\", \"test\"])\n",
        "        else:\n",
        "            grad_pd_sum = grad_pd_sum.append(pd.DataFrame(pd_d0, columns=pd_c))\n",
        "            grad_pd_mean = grad_pd_mean.append(pd.DataFrame(pd_d1, columns=pd_c))\n",
        "            grad_pd_var = grad_pd_var.append(pd.DataFrame(pd_d2, columns=pd_c))\n",
        "\n",
        "            loss_pd = loss_pd.append(pd.DataFrame(np.append(train_metric[0]/train_metric[2], test_metric[0]/test_metric[2]).reshape(1, -1), \n",
        "                                                  columns=[\"train\", \"test\"]))\n",
        "            acc_pd  = acc_pd.append (pd.DataFrame(np.append(train_metric[1]/train_metric[2], test_metric[1]/test_metric[2]).reshape(1, -1), \n",
        "                                                  columns=[\"train\", \"test\"]))\n",
        "            time_pd = time_pd.append(pd.DataFrame([[t_train, t_grad, t_test]], columns=[\"train\", \"grad\", \"test\"]))\n",
        "\n",
        "        # 绘图\n",
        "        grad_plot.update(grad_pd_sum, grad_pd_mean, grad_pd_var, loss_pd, acc_pd, time_pd)\n",
        "            \n",
        "        # 保存数据\n",
        "        save_name = os.path.splitext(save_csv)[0]\n",
        "        grad_plot.save(save_name)\n",
        "        table = pd.DataFrame({\n",
        "            \"train_loss\"    : train_metric[0]/train_metric[2],\n",
        "            \"train_accurate\": train_metric[1]/train_metric[2],\n",
        "            \"test_loss\"     : test_metric[0]/test_metric[2],\n",
        "            \"test_accurate\" : test_metric[1]/test_metric[2],\n",
        "        })\n",
        "        table.to_csv(save_csv)\n",
        "\n",
        "        if not os.path.exists(f\"./{save_name}\"):\n",
        "            os.mkdir(f\"./{save_name}\")\n",
        "        torch.save(net, f\"./{save_name}/{epoch}.pt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nZYyPPnjot-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual block\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def conv_block(input_channels, num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
        "        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))\n",
        "    \n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_convs, input_channels, num_channels):\n",
        "        super().__init__()\n",
        "        layer = []\n",
        "        for i in range(num_convs):\n",
        "            layer.append(conv_block(num_channels*i + input_channels, num_channels))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return X\n",
        "\n",
        "def transition_block(input_channels, num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
        "        nn.Conv2d(input_channels, num_channels, kernel_size=1),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2))"
      ],
      "metadata": {
        "id": "0X1TJwvvov2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "lr, num_epochs = 0.1, 50\n",
        "batch = 256\n",
        "\n",
        "b1 = nn.Sequential(\n",
        "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
        "    nn.BatchNorm2d(64), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "\n",
        "# num_channels为当前的通道数\n",
        "num_channels, growth_rate = 64, 32\n",
        "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
        "blks = []\n",
        "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
        "    blks.append(DenseBlock(num_convs, num_channels, growth_rate))\n",
        "    # 上一个稠密块的输出通道数\n",
        "    num_channels += num_convs * growth_rate\n",
        "    # 在稠密块之间添加一个转换层，使通道数量减半\n",
        "    if i != len(num_convs_in_dense_blocks) - 1:\n",
        "        blks.append(transition_block(num_channels, num_channels // 2))\n",
        "        num_channels = num_channels // 2\n",
        "\n",
        "net = nn.Sequential(\n",
        "    b1, *blks,\n",
        "    nn.BatchNorm2d(num_channels), nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(num_channels, 10))\n",
        "\n",
        "x = torch.rand(size=(2,1, 224,224), dtype=torch.float32)\n",
        "for layer in net:\n",
        "    x = layer(x)\n",
        "    print(layer.__class__.__name__,'output shape: \\t',x.shape)\n",
        "\n",
        "# train_iter, test_iter = get_data_iter(batch)\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch, resize=96)\n",
        "train(net, train_iter, test_iter, num_epochs, lr, device, save_csv=\"test_lre-1.csv\", init=True)"
      ],
      "metadata": {
        "id": "xkEEbPpZozTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H50FYzX65P1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}