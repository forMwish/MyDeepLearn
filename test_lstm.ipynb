{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDPENoxLSOzoBn8Er+8DG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forMwish/MyDeepLearn/blob/master/test_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 环境配置\n",
        "\n"
      ],
      "metadata": {
        "id": "bKeaj5KGQSns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm7erzgZkmiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ef3c99-3a0c-470d-b570-1f66704c53ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# 挂载 gdrive，选择\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "gdrive_path = '/gdrive'\n",
        "drive.mount(gdrive_path, force_remount=True)\n",
        "\n",
        "os.chdir(\"%s/MyDrive\"%gdrive_path)\n",
        "try:\n",
        "    os.mkdir(\"./test_lstm\")\n",
        "    os.chdir(\"./test_lstm\")\n",
        "except:\n",
        "    os.chdir(\"./test_lstm\")\n",
        "    os.system(\"rm ./*\")\n",
        "\n",
        "# 解决 matplot 相关问题\n",
        "os.system(\"pip uninstall matplotlib\")\n",
        "os.system(\"pip install matplotlib==3.1.3\")\n",
        "\n",
        "os.system(\"pip install onnx\")\n",
        "os.system(\"pip install onnxruntime\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 其它配置\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# notebook 设置tag补全\n",
        "%config Completer.use_jedi = False\n",
        "\n",
        "# 优先使用 gpu 设备\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"use device:\", device)\n",
        "\n",
        "# pyplot 使用黑暗模式\n",
        "plt.style.use(\"default\")\n",
        "# plt.style.use(\"dark_background\")\n",
        "\n",
        "# pytorch 随机种子固定\n",
        "torch.manual_seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# numpy 随机种子固定\n",
        "np.random.seed(0)\n",
        "\n",
        "# python 随机种子固定\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "nAsBwDPXk1d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af6f5a8-d0c8-4e48-c584-3d4ef7ae4023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. pytorch 部分\n",
        "从 ocr_0_for_test.onnx 模型中提取相关参数，反量化后加载到 pytorch lstm 中 <br>\n",
        "从 rnn_in.npy 加载输入 x <br>\n",
        "从 fc_in.npy 加载对比的输出 y <br>\n",
        "\n"
      ],
      "metadata": {
        "id": "kFGcdmMXQYEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch 构建测试demo，并导出 onnx\n",
        "from torch import nn\n",
        "\n",
        "class TestLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bidirectional):\n",
        "        super().__init__()\n",
        "        self.lstm = torch.nn.LSTM(input_size=input_size, hidden_size=hidden_size, \n",
        "                          bias=True, batch_first=True, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, X):\n",
        "        y = self.lstm(X)\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "JqWS7hE4lIkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "x = torch.tensor(np.load(\"../ocr_lstm/rnn_in.npy\"), dtype=torch.float32)\n",
        "y = torch.tensor(np.load(\"../ocr_lstm/fc_in.npy\"), dtype=torch.float32)\n",
        "\n",
        "import onnx\n",
        "\n",
        "quant_model = onnx.load(\"../ocr_lstm/ocr_0_for_test.onnx\")\n",
        "for tensor in quant_model.graph.initializer:\n",
        "    if \"bias_hh_l0\" in tensor.name:\n",
        "        print(tensor.name)"
      ],
      "metadata": {
        "id": "zt0_zWAk2019"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load para from quant model\n",
        "\n",
        "def find_tensors_by_name_suffix(name, initializer):\n",
        "    \"\"\" 在 tensor 中查找 name == tensor.name[-len(name):] 的 tensor \n",
        "        返回所有符合条件的 tensor_list\n",
        "    \"\"\"\n",
        "    tensor_list=[]\n",
        "    for tensor in initializer:\n",
        "        if name == tensor.name[-len(name):]:\n",
        "            tensor_list.append(tensor)\n",
        "    return tensor_list\n",
        "\n",
        "def get_tensor_from_quant_model(name, quant_model):\n",
        "    \"\"\"获取参数以及对应 scale，并返回\n",
        "    \"\"\"\n",
        "    ret = find_tensors_by_name_suffix(name, quant_model.graph.initializer)\n",
        "    assert len(ret) == 1\n",
        "    tensor = torch.tensor(ret[0].float_data, dtype=torch.float32).reshape(list(ret[0].dims))\n",
        "    # print(name)\n",
        "    # print(tensor.shape)\n",
        "\n",
        "    key = f\"{name}_quant_scale\"\n",
        "    ret = find_tensors_by_name_suffix(key, quant_model.graph.initializer)\n",
        "    assert len(ret) == 1\n",
        "    scale = torch.tensor(ret[0].float_data, dtype=torch.float32).reshape(list(ret[0].dims))\n",
        "    # print(scale.shape)\n",
        "\n",
        "    # # 特殊处理 bias_ih_l0[512:] bias_ih_l0_reverse[512:] 为 0\n",
        "    # if name in [\"bias_ih_l0\", \"bias_ih_l0_reverse\"]:\n",
        "    #     print(\"=========\", name, tensor.shape)\n",
        "    #     tensor[:, 512:] = 0\n",
        "\n",
        "    return tensor, scale\n",
        "\n",
        "def get_state_dict_from_quant_model(keys, quant_model):\n",
        "    state_dict = {}\n",
        "    for name in keys:\n",
        "        # print(name)\n",
        "        tensor, scale = get_tensor_from_quant_model(name, quant_model)\n",
        "        if name in [\"weight_ih_l0\", \"weight_hh_l0\", \"weight_ih_l0_reverse\", \"weight_hh_l0_reverse\"]:\n",
        "            scale = scale.reshape((-1, 1))\n",
        "            tensor.squeeze_()\n",
        "            # print(\"tensor:\", tensor.shape)\n",
        "            # print(\"scale:\", scale.shape)\n",
        "            tensor = tensor*scale\n",
        "            state_dict[name] = tensor\n",
        "        if name in [\"bias_ih_l0\", \"bias_ih_l0_reverse\"]:\n",
        "            tensor.squeeze_()\n",
        "            # print(\"====tensor:\", tensor.shape)\n",
        "            # print(\"====scale:\", scale.shape)\n",
        "            tensor = tensor*scale\n",
        "            # print(tensor[511:])\n",
        "            assert len(tensor.shape) == 1\n",
        "            state_dict[name] = tensor[:int(tensor.shape[0]/2)]\n",
        "            # print(\"====0tensor:\", state_dict[name].shape)\n",
        "            new_name = name.replace(\"bias_ih_l0\", \"bias_hh_l0\")\n",
        "            state_dict[new_name] = tensor[int(tensor.shape[0]/2):]\n",
        "            # print(\"====1tensor:\", state_dict[new_name].shape)\n",
        "    return state_dict\n",
        "\n",
        "\n",
        "model = TestLSTM(input_size=256, hidden_size=128, bidirectional=True)\n",
        "\n",
        "# keys = [\"weight_ih_l0\", \"weight_hh_l0\", \"bias_ih_l0\", \"bias_hh_l0\"]\n",
        "keys = [\"weight_ih_l0\", \"weight_hh_l0\", \"bias_ih_l0\", \n",
        "        \"weight_ih_l0_reverse\", \"weight_hh_l0_reverse\", \"bias_ih_l0_reverse\"]\n",
        "new_state_dict = get_state_dict_from_quant_model(keys, quant_model)\n",
        "\n",
        "model.lstm.load_state_dict(new_state_dict, strict=True)\n",
        "\n",
        "\n",
        "# for i in model.lstm.named_parameters():\n",
        "#     print(i)\n",
        "#     break"
      ],
      "metadata": {
        "id": "Eo3mo4FL1vIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce79021-f6fe-4dae-8883-9da70792f304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_hat, status = model(x)"
      ],
      "metadata": {
        "id": "DC2NbE_GAFKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 误差计算\n",
        "o_scale = 128\n",
        "\n",
        "y_quant = np.clip((y.squeeze_().numpy()*o_scale), -128, 127).round().astype(np.int8)\n",
        "y_hat_quant = np.clip((y_hat.squeeze_().numpy()*o_scale), -128, 127).round().astype(np.int8)\n",
        "error = np.abs(y_hat_quant.astype(np.int32) - y_quant.astype(np.int32))\n",
        "assert len(error.shape)==2\n",
        "print(f\"error_quant:\\n\\tmax:{error.max()} index:({int(error.argmax()/error.shape[1])}, {error.argmax()%error.shape[1]})\")\n",
        "print(np.sum(error))\n",
        "\n",
        "np.save(\"error_quant\", error)\n",
        "np.save(\"y_quant\", y_quant)\n",
        "np.save(\"y_hat_quant\", y_hat_quant)"
      ],
      "metadata": {
        "id": "u3kGSr35DbhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee30aca-01f6-458b-d101-327c18f78d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error_quant:\n",
            "\tmax:3 index:(153, 168)\n",
            "4315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. onnx 部分"
      ],
      "metadata": {
        "id": "aeyOZK-fLtNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 转换为 onnx\n",
        "torch.onnx.export(model, x, \"test_lstm_tmp.onnx\", opset_version=12, \n",
        "                  input_names=['input'], output_names=['output'])"
      ],
      "metadata": {
        "id": "4Fux5D69Er08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c464ead-83a8-4ea9-d0ad-7d40b28474de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:2192: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
            "  \"or define the initial states (h0/c0) as inputs of the model. \")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the onnx model\n",
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(\"test_lstm_tmp.onnx\")\n",
        "onnx_model = onnx.shape_inference.infer_shapes(onnx_model)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx.save(onnx_model, \"test_lstm_tmp.onnx\")"
      ],
      "metadata": {
        "id": "U5ZZPcbonqtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create inference session\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "ort_sess = ort.InferenceSession(\"test_lstm_tmp.onnx\")\n",
        "outputs = ort_sess.run(None, {'input': x.numpy()})\n",
        "# print(\"onnxruntime output:\", outputs)\n",
        "y_hat_onnx = outputs[0]\n",
        "# print(\"y_hat_onnx.shape:\", y_hat_onnx.shape)\n",
        "# print(\"y.shape:\", y.numpy().shape)\n",
        "\n",
        "y_quant = np.clip((y.squeeze_().numpy()*o_scale), -128, 127).round().astype(np.int8)\n",
        "y_hat_onnx_quant = np.clip(np.squeeze(y_hat_onnx*o_scale), -128, 127).round().astype(np.int8)\n",
        "\n",
        "error_onnx = np.abs(y_hat_onnx_quant.astype(np.int32) - y_quant.astype(np.int32))\n",
        "\n",
        "print(\"error_onnx.shape:\", error_onnx.shape)\n",
        "\n",
        "print(f\"error_onnx_quant:\\n\\tmax:{error_onnx.max()} index:({int(error_onnx.argmax()/error_onnx.shape[1])}, {error_onnx.argmax()%error_onnx.shape[1]})\")\n",
        "print(np.sum(error_onnx))\n",
        "\n",
        "np.save(\"error_onnx_quant\", error_onnx)\n",
        "np.save(\"y_quant\", y_quant)\n",
        "np.save(\"y_hat_onnx_quant\", y_hat_onnx_quant)\n"
      ],
      "metadata": {
        "id": "DhKoC1QCq4Ua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb4da92d-1b91-40ab-d471-ac2cc3fbfc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error_onnx.shape: (512, 256)\n",
            "error_onnx_quant:\n",
            "\tmax:3 index:(153, 168)\n",
            "4314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 比较 pytorch 和 onnx 的参数分布\n",
        "验证是否参数排布如猜想的：pytorch 为 ifco 排布，而 onnx 为 iofc 排布"
      ],
      "metadata": {
        "id": "BTMtkwoI0H9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# onnx_W\n",
        "# onnx_R\n",
        "# onnx_B\n",
        "\n",
        "import struct\n",
        "\n",
        "def convert_bytes_to_list(input:bytes, format:str):\n",
        "    \"\"\" bytes 转 list\n",
        "    \"\"\"\n",
        "    iter = struct.iter_unpack(format, input)\n",
        "    data_list = []\n",
        "    for data in iter:\n",
        "        data_list.append(data)\n",
        "    return data_list\n",
        "\n",
        "def convert_initializer_to_tensor(name:str, initializer):\n",
        "    \"\"\" 从 initializer 中查找对应 name 的 tensor， 并转换为 pytorch.tensor\n",
        "        未找到则返回 None\n",
        "    \"\"\"\n",
        "    for tensor in initializer:\n",
        "        print(tensor.name)\n",
        "        if tensor.name == name:\n",
        "            shape=list(tensor.dims)\n",
        "            print(shape)\n",
        "            print(tensor.data_type)\n",
        "\n",
        "            if tensor.data_type == 1:\n",
        "                assert len(tensor.float_data) == 0\n",
        "                ret = convert_bytes_to_list(tensor.raw_data, \"<f\")\n",
        "                return torch.tensor(ret, dtype=torch.float32).reshape(shape)\n",
        "            else:\n",
        "                assert False\n",
        "    \n",
        "    return None\n",
        "\n",
        "for tensor in onnx_model.graph.initializer:\n",
        "    if tensor.name == \"onnx::LSTM_194\":\n",
        "        onnx_W = convert_initializer_to_tensor(tensor.name, onnx_model.graph.initializer)\n",
        "        print(f\"onnx_W:\\n  shape:{list(onnx_W.shape)}\")\n",
        "        print(f\"  onnx_W[:10]: {onnx_W.reshape(-1)[:10]}\")\n",
        "\n",
        "        # print(new_state_dict.keys())\n",
        "        torch_wi = new_state_dict[\"weight_ih_l0\"]\n",
        "        h_size = int(torch_wi.shape[0]/4)\n",
        "        torch_wi_0 = torch.cat((torch_wi[:h_size, :], \n",
        "                               torch_wi[3*h_size:, :],\n",
        "                               torch_wi[h_size:2*h_size, :],\n",
        "                               torch_wi[2*h_size:3*h_size, :]\n",
        "                               ), dim=0)\n",
        "        torch_wi = new_state_dict[\"weight_ih_l0_reverse\"]\n",
        "        torch_wi_1 = torch.cat((torch_wi[:h_size, :], \n",
        "                               torch_wi[3*h_size:, :],\n",
        "                               torch_wi[h_size:2*h_size, :],\n",
        "                               torch_wi[2*h_size:3*h_size, :]\n",
        "                               ), dim=0)\n",
        "\n",
        "        torch_w = torch.cat((\n",
        "                    torch_wi_0.unsqueeze(dim=0),\n",
        "                    torch_wi_1.unsqueeze(dim=0),\n",
        "                    ), dim=0)\n",
        "        \n",
        "        print(f\"torch_w:\\n  shape:{torch_w.shape}\")\n",
        "        print(f\"  torch_w[:10]: {torch_w.reshape(-1)[:10]}\")\n",
        "        \n",
        "        error = np.abs((onnx_W - torch_w).numpy()).sum()\n",
        "\n",
        "        # b0 = 2\n",
        "        # b1 = 2\n",
        "        # error = np.abs((onnx_W[0,b0*128:(b0+1)*128,:] - torch_w[0,b1*128:(b1+1)*128,:]).numpy()).sum()\n",
        "        print(f\"onnx_W error:{error}\\n\")\n",
        "\n",
        "    elif tensor.name == \"onnx::LSTM_195\":\n",
        "        onnx_R = convert_initializer_to_tensor(tensor.name, onnx_model.graph.initializer)\n",
        "        print(f\"onnx_R:\\n  shape:{list(onnx_R.shape)}\")\n",
        "        print(f\"  onnx_R[:10]: {onnx_R.reshape(-1)[:10]}\")\n",
        "\n",
        "        torch_ri = new_state_dict[\"weight_hh_l0\"]\n",
        "        h_size = int(torch_ri.shape[0]/4)\n",
        "        torch_ri_0 = torch.cat((torch_ri[:h_size, :], \n",
        "                               torch_ri[3*h_size:, :],\n",
        "                               torch_ri[h_size:2*h_size, :],\n",
        "                               torch_ri[2*h_size:3*h_size, :]\n",
        "                               ), dim=0)\n",
        "        \n",
        "        torch_ri = new_state_dict[\"weight_hh_l0_reverse\"]\n",
        "        torch_ri_1 = torch.cat((torch_ri[:h_size, :], \n",
        "                               torch_ri[3*h_size:, :],\n",
        "                               torch_ri[h_size:2*h_size, :],\n",
        "                               torch_ri[2*h_size:3*h_size, :]\n",
        "                               ), dim=0)\n",
        "        torch_r = torch.cat((\n",
        "                    torch_ri_0.unsqueeze(dim=0),\n",
        "                    torch_ri_1.unsqueeze(dim=0),\n",
        "                    ), dim=0)\n",
        "        \n",
        "        print(f\"torch_r:\\n  shape:{torch_r.shape}\")\n",
        "        print(f\"  onnx_R[:10]: {onnx_R.reshape(-1)[:10]}\")\n",
        "\n",
        "        error = np.abs((onnx_R - torch_r).numpy()).sum()\n",
        "        print(f\"onnx_R error:{error}\\n\")\n",
        "\n",
        "    elif tensor.name == \"onnx::LSTM_193\":\n",
        "        onnx_B = convert_initializer_to_tensor(tensor.name, onnx_model.graph.initializer)\n",
        "        print(\"onnx_B:\\n  shape:\", list(onnx_B.shape))\n",
        "        print(f\"  onnx_B[:10]: {onnx_B.reshape(-1)[:10]}\")\n",
        "\n",
        "        torch_bi = new_state_dict[\"bias_ih_l0\"]\n",
        "        h_size = int(torch_bi.shape[0]/4)\n",
        "        torch_bi_0 = torch.cat((torch_bi[:h_size], \n",
        "                               torch_bi[3*h_size:],\n",
        "                               torch_bi[h_size:2*h_size],\n",
        "                               torch_bi[2*h_size:3*h_size]\n",
        "                               ), dim=0)\n",
        "        \n",
        "        torch_bi = new_state_dict[\"bias_hh_l0\"]\n",
        "        torch_bi_1 = torch.cat((torch_bi[:h_size], \n",
        "                               torch_bi[3*h_size:],\n",
        "                               torch_bi[h_size:2*h_size],\n",
        "                               torch_bi[2*h_size:3*h_size]\n",
        "                               ), dim=0)\n",
        "        \n",
        "        torch_bi = new_state_dict[\"bias_ih_l0_reverse\"]\n",
        "        torch_bi_2 = torch.cat((torch_bi[:h_size], \n",
        "                               torch_bi[3*h_size:],\n",
        "                               torch_bi[h_size:2*h_size],\n",
        "                               torch_bi[2*h_size:3*h_size]\n",
        "                               ), dim=0)\n",
        "        \n",
        "        torch_bi = new_state_dict[\"bias_hh_l0_reverse\"]\n",
        "        torch_bi_3 = torch.cat((torch_bi[:h_size], \n",
        "                               torch_bi[3*h_size:],\n",
        "                               torch_bi[h_size:2*h_size],\n",
        "                               torch_bi[2*h_size:3*h_size]\n",
        "                               ), dim=0)\n",
        "        \n",
        "\n",
        "        torch_b_0 = torch.cat((\n",
        "                    torch_bi_0,\n",
        "                    torch_bi_1,\n",
        "                    ), dim=0).unsqueeze(0)\n",
        "        torch_b_1 = torch.cat((\n",
        "                    torch_bi_2,\n",
        "                    torch_bi_3,\n",
        "                    ), dim=0).unsqueeze(0)\n",
        "\n",
        "        torch_b = torch.cat((\n",
        "                    torch_b_0,\n",
        "                    torch_b_1,\n",
        "                    ), dim=0)\n",
        "        print(\"torch_b:\\n  shape:\", list(torch_b.shape))\n",
        "        print(f\"  torch_b[:10]: {torch_b.reshape(-1)[:10]}\")\n",
        "\n",
        "        error = np.abs((onnx_B - torch_b).numpy()).sum()\n",
        "        print(f\"onnx_R error:{error}\\n\")\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FyvanqENTc7",
        "outputId": "96bd2678-a3e3-4390-95a9-fb02b53e4dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "onnx::LSTM_193\n",
            "[2, 1024]\n",
            "1\n",
            "onnx_B:\n",
            "  shape: [2, 1024]\n",
            "  onnx_B[:10]: tensor([ 0.0063,  0.0000,  0.0293,  0.0142,  0.0195, -0.0005,  0.0210,  0.0112,\n",
            "         0.0137, -0.0181])\n",
            "torch_b:\n",
            "  shape: [2, 1024]\n",
            "  torch_b[:10]: tensor([ 0.0063,  0.0000,  0.0293,  0.0142,  0.0195, -0.0005,  0.0210,  0.0112,\n",
            "         0.0137, -0.0181])\n",
            "onnx_R error:0.0\n",
            "\n",
            "onnx::LSTM_193\n",
            "onnx::LSTM_194\n",
            "[2, 512, 256]\n",
            "1\n",
            "onnx_W:\n",
            "  shape:[2, 512, 256]\n",
            "  onnx_W[:10]: tensor([ 0.0664,  0.0273,  0.0078,  0.0000,  0.0234, -0.0039, -0.0234,  0.0039,\n",
            "        -0.0586,  0.0273])\n",
            "torch_w:\n",
            "  shape:torch.Size([2, 512, 256])\n",
            "  torch_w[:10]: tensor([ 0.0664,  0.0273,  0.0078,  0.0000,  0.0234, -0.0039, -0.0234,  0.0039,\n",
            "        -0.0586,  0.0273])\n",
            "onnx_W error:0.0\n",
            "\n",
            "onnx::LSTM_193\n",
            "onnx::LSTM_194\n",
            "onnx::LSTM_195\n",
            "[2, 512, 128]\n",
            "1\n",
            "onnx_R:\n",
            "  shape:[2, 512, 128]\n",
            "  onnx_R[:10]: tensor([ 0.0234,  0.0156, -0.0156,  0.0078,  0.0156,  0.0117, -0.0117,  0.0117,\n",
            "        -0.0391,  0.0352])\n",
            "torch_r:\n",
            "  shape:torch.Size([2, 512, 128])\n",
            "  onnx_R[:10]: tensor([ 0.0234,  0.0156, -0.0156,  0.0078,  0.0156,  0.0117, -0.0117,  0.0117,\n",
            "        -0.0391,  0.0352])\n",
            "onnx_R error:0.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3Z5dz2nX0eCE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}